"""
RAGçŸ¥è¯†åº“æ¨¡å—
ç”¨äºå­˜å‚¨å’Œç®¡ç†æˆªå›¾çŸ¥è¯†åº“å’Œæ“ä½œç»éªŒçŸ¥è¯†åº“
"""

import os
import json
import time
import hashlib
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass, asdict
from PIL import Image
import base64
import io
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pickle


@dataclass
class TaskExperience:
    """ä»»åŠ¡ç»éªŒæ•°æ®ç»“æ„"""
    task_id: str
    task_description: str
    task_goal: str
    success: bool
    total_steps: int
    total_tokens: int
    screenshots: List[str]  # æˆªå›¾è·¯å¾„åˆ—è¡¨
    actions: List[Dict]  # æ“ä½œåºåˆ—
    thoughts: List[str]  # æ€è€ƒè¿‡ç¨‹
    action_usefulness: List[Dict] = None  # æ–°å¢ï¼šæ“ä½œæœ‰ç”¨æ€§è¯„ä¼°
    error_message: Optional[str] = None
    similarity_score: Optional[float] = None
    usage_count: int = 0  # æ–°å¢ï¼šè®°å½•è¢«æ£€ç´¢ä½¿ç”¨çš„æ¬¡æ•°
    failure_count: int = 0  # æ–°å¢ï¼šè®°å½•æ£€ç´¢ä½¿ç”¨ä½†ä»»åŠ¡å¤±è´¥çš„æ¬¡æ•°
    created_at: float = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()
        if self.action_usefulness is None:
            self.action_usefulness = []
        if self.usage_count is None:
            self.usage_count = 0
        if self.failure_count is None:
            self.failure_count = 0


@dataclass
class ScreenshotKnowledge:
    """æˆªå›¾çŸ¥è¯†æ•°æ®ç»“æ„"""
    screenshot_id: str
    screenshot_path: str
    screenshot_base64: str
    task_context: str  # ä»»åŠ¡ä¸Šä¸‹æ–‡æè¿°
    successful_actions: List[Dict]  # åœ¨æ­¤æˆªå›¾ä¸‹æˆåŠŸçš„æ“ä½œ
    failed_actions: List[Dict]  # åœ¨æ­¤æˆªå›¾ä¸‹å¤±è´¥çš„æ“ä½œ
    ui_elements: Dict[str, Any]  # UIå…ƒç´ æè¿°
    similarity_tags: List[str]  # ç›¸ä¼¼æ€§æ ‡ç­¾
    usage_count: int = 0  # æ–°å¢ï¼šè®°å½•è¢«æ£€ç´¢ä½¿ç”¨çš„æ¬¡æ•°
    failure_count: int = 0  # æ–°å¢ï¼šè®°å½•æ£€ç´¢ä½¿ç”¨ä½†ä»»åŠ¡å¤±è´¥çš„æ¬¡æ•°
    created_at: float = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()
        if self.usage_count is None:
            self.usage_count = 0
        if self.failure_count is None:
            self.failure_count = 0


class RAGKnowledgeBase:
    """RAGçŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self, knowledge_dir: str = "knowledge_base"):
        self.knowledge_dir = knowledge_dir
        self.experience_file = os.path.join(knowledge_dir, "task_experiences.json")
        self.screenshot_file = os.path.join(knowledge_dir, "screenshot_knowledge.json")
        self.vectorizer_file = os.path.join(knowledge_dir, "tfidf_vectorizer.pkl")
        self.matrix_file = os.path.join(knowledge_dir, "similarity_matrix.pkl")
        
        # åˆ›å»ºçŸ¥è¯†åº“ç›®å½•
        os.makedirs(knowledge_dir, exist_ok=True)
        
        # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
        self.task_experiences: List[TaskExperience] = []
        self.screenshot_knowledge: List[ScreenshotKnowledge] = []
        
        # å‘é‡åŒ–å·¥å…·
        self.vectorizer = None
        self.similarity_matrix = None
        
        # åŠ è½½å·²æœ‰æ•°æ®
        self.load_knowledge()
        
    def load_knowledge(self):
        """åŠ è½½å·²æœ‰çŸ¥è¯†åº“æ•°æ®"""
        try:
            # åŠ è½½ä»»åŠ¡ç»éªŒ
            if os.path.exists(self.experience_file):
                with open(self.experience_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.task_experiences = [TaskExperience(**item) for item in data]
                    print(f"âœ… åŠ è½½äº† {len(self.task_experiences)} æ¡ä»»åŠ¡ç»éªŒ")
            
            # åŠ è½½æˆªå›¾çŸ¥è¯†
            if os.path.exists(self.screenshot_file):
                with open(self.screenshot_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.screenshot_knowledge = [ScreenshotKnowledge(**item) for item in data]
                    print(f"âœ… åŠ è½½äº† {len(self.screenshot_knowledge)} æ¡æˆªå›¾çŸ¥è¯†")
            
            # åŠ è½½å‘é‡åŒ–æ•°æ®
            if os.path.exists(self.vectorizer_file) and os.path.exists(self.matrix_file):
                with open(self.vectorizer_file, 'rb') as f:
                    self.vectorizer = pickle.load(f)
                with open(self.matrix_file, 'rb') as f:
                    self.similarity_matrix = pickle.load(f)
                print("âœ… åŠ è½½äº†å‘é‡åŒ–æ•°æ®")
                
        except Exception as e:
            print(f"âš ï¸ åŠ è½½çŸ¥è¯†åº“æ•°æ®æ—¶å‡ºé”™: {e}")
    
    def save_knowledge(self):
        """ä¿å­˜çŸ¥è¯†åº“æ•°æ®"""
        try:
            # ä¿å­˜ä»»åŠ¡ç»éªŒ
            with open(self.experience_file, 'w', encoding='utf-8') as f:
                data = [asdict(exp) for exp in self.task_experiences]
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜æˆªå›¾çŸ¥è¯†
            with open(self.screenshot_file, 'w', encoding='utf-8') as f:
                data = [asdict(sk) for sk in self.screenshot_knowledge]
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜å‘é‡åŒ–æ•°æ®
            if self.vectorizer is not None:
                with open(self.vectorizer_file, 'wb') as f:
                    pickle.dump(self.vectorizer, f)
            if self.similarity_matrix is not None:
                with open(self.matrix_file, 'wb') as f:
                    pickle.dump(self.similarity_matrix, f)
                    
            print("ğŸ’¾ çŸ¥è¯†åº“æ•°æ®å·²ä¿å­˜")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜çŸ¥è¯†åº“æ•°æ®æ—¶å‡ºé”™: {e}")
    
    def add_task_experience(self, 
                           task_description: str,
                           task_goal: str,
                           success: bool,
                           total_steps: int,
                           total_tokens: int,
                           screenshots: List[str],
                           actions: List[Dict],
                           thoughts: List[str],
                           action_usefulness: List[Dict] = None,  # æ–°å¢ï¼šæ“ä½œæœ‰ç”¨æ€§è¯„ä¼°
                           error_message: Optional[str] = None) -> str:
        """æ·»åŠ ä»»åŠ¡ç»éªŒ"""
        task_id = hashlib.md5(f"{task_description}_{time.time()}".encode()).hexdigest()[:8]
        
        experience = TaskExperience(
            task_id=task_id,
            task_description=task_description,
            task_goal=task_goal,
            success=success,
            total_steps=total_steps,
            total_tokens=total_tokens,
            screenshots=screenshots,
            actions=actions,
            thoughts=thoughts,
            action_usefulness=action_usefulness,  # æ–°å¢ï¼šæ“ä½œæœ‰ç”¨æ€§è¯„ä¼°
            error_message=error_message
        )
        
        self.task_experiences.append(experience)
        self.update_vectorization()
        return task_id
    
    def add_screenshot_knowledge(self,
                                screenshot_path: str,
                                screenshot_base64: str,
                                task_context: str,
                                successful_actions: List[Dict],
                                failed_actions: List[Dict],
                                ui_elements: Dict[str, Any],
                                similarity_tags: List[str]) -> str:
        """æ·»åŠ æˆªå›¾çŸ¥è¯†"""
        screenshot_id = hashlib.md5(f"{screenshot_path}_{time.time()}".encode()).hexdigest()[:8]
        
        knowledge = ScreenshotKnowledge(
            screenshot_id=screenshot_id,
            screenshot_path=screenshot_path,
            screenshot_base64=screenshot_base64,
            task_context=task_context,
            successful_actions=successful_actions,
            failed_actions=failed_actions,
            ui_elements=ui_elements,
            similarity_tags=similarity_tags
        )
        
        self.screenshot_knowledge.append(knowledge)
        self.update_vectorization()
        return screenshot_id
    
    def update_vectorization(self):
        """æ›´æ–°å‘é‡åŒ–æ•°æ®ç”¨äºç›¸ä¼¼æ€§æœç´¢"""
        if not self.task_experiences:
            return
        
        # å‡†å¤‡æ–‡æœ¬æ•°æ®
        texts = []
        for exp in self.task_experiences:
            text = f"{exp.task_description} {exp.task_goal} {' '.join(exp.thoughts)}"
            texts.append(text)
        
        # TF-IDFå‘é‡åŒ–
        self.vectorizer = TfidfVectorizer(
            max_features=1000,
            stop_words=None,
            ngram_range=(1, 2)
        )
        tfidf_matrix = self.vectorizer.fit_transform(texts)
        
        # è®¡ç®—ç›¸ä¼¼æ€§çŸ©é˜µ
        self.similarity_matrix = cosine_similarity(tfidf_matrix)

        self.save_knowledge()
    
    def search_similar_tasks(self, 
                            current_task: str, 
                            top_k: int = 5,
                            only_successful: bool = False) -> List[TaskExperience]:
        """æœç´¢ç›¸ä¼¼ä»»åŠ¡"""
        if self.vectorizer is None or self.similarity_matrix is None:
            return []
        
        # å‘é‡åŒ–å½“å‰ä»»åŠ¡
        current_vector = self.vectorizer.transform([current_task])
        
        # è®¡ç®—ä¸æ‰€æœ‰å†å²ä»»åŠ¡çš„ç›¸ä¼¼æ€§
        similarities = cosine_similarity(current_vector, self.vectorizer.transform([
            f"{exp.task_description} {exp.task_goal}" for exp in self.task_experiences
        ]))[0]
        
        # è·å–æœ€ç›¸ä¼¼çš„ä»»åŠ¡ç´¢å¼•
        similar_indices = np.argsort(similarities)[::-1]
        
        # è®°å½•è¢«æ£€ç´¢çš„ç»éªŒç´¢å¼•ï¼Œä»¥ä¾¿åç»­æ›´æ–°å¤±è´¥è®¡æ•°
        self._current_retrieved_task_indices = []
        
        results = []
        for idx in similar_indices[:top_k * 2]:  # å–æ›´å¤šå€™é€‰
            exp = self.task_experiences[idx]
            exp.similarity_score = float(similarities[idx])
            
            # å¢åŠ ä½¿ç”¨è®¡æ•°
            self.task_experiences[idx].usage_count += 1
            # è®°å½•è¢«æ£€ç´¢çš„ç´¢å¼•
            self._current_retrieved_task_indices.append(idx)
            
            if only_successful and not exp.success:
                continue
                
            results.append(exp)
            
            if len(results) >= top_k:
                break
        
        # ä¿å­˜æ›´æ–°åçš„ä½¿ç”¨è®¡æ•°
        self.save_knowledge()
        
        return results
    
    def search_similar_screenshots(self, 
                                  current_context: str,
                                  top_k: int = 3) -> List[ScreenshotKnowledge]:
        """æœç´¢ç›¸ä¼¼æˆªå›¾"""
        if not self.screenshot_knowledge:
            return []
        
        # ç®€å•çš„æ–‡æœ¬åŒ¹é…æœç´¢
        results = []
        current_lower = current_context.lower()
        matched_indices = []  # è®°å½•åŒ¹é…çš„ç´¢å¼•ï¼Œç”¨äºæ›´æ–°ä½¿ç”¨è®¡æ•°
        
        # è®°å½•è¢«æ£€ç´¢çš„æˆªå›¾ç´¢å¼•ï¼Œä»¥ä¾¿åç»­æ›´æ–°å¤±è´¥è®¡æ•°
        self._current_retrieved_screenshot_indices = []
        
        for idx, sk in enumerate(self.screenshot_knowledge):
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0
            
            # ä»»åŠ¡ä¸Šä¸‹æ–‡åŒ¹é…
            if any(word in sk.task_context.lower() for word in current_lower.split()):
                score += 3
            
            # æ ‡ç­¾åŒ¹é…
            for tag in sk.similarity_tags:
                if tag.lower() in current_lower:
                    score += 2
            
            # UIå…ƒç´ åŒ¹é…
            for element_type, element_info in sk.ui_elements.items():
                if isinstance(element_info, str) and element_info.lower() in current_lower:
                    score += 1
            
            if score > 0:
                results.append((sk, score))
                matched_indices.append(idx)
                # è®°å½•è¢«æ£€ç´¢çš„ç´¢å¼•
                self._current_retrieved_screenshot_indices.append(idx)
        
        # æ›´æ–°åŒ¹é…é¡¹çš„ä½¿ç”¨è®¡æ•°
        for idx in matched_indices:
            self.screenshot_knowledge[idx].usage_count += 1
        
        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        final_results = [sk for sk, _ in results[:top_k]]
        
        # ä¿å­˜æ›´æ–°åçš„ä½¿ç”¨è®¡æ•°
        if matched_indices:
            self.save_knowledge()
        
        return final_results
    
    def get_successful_actions_for_context(self, context: str) -> List[Dict]:
        """æ ¹æ®ä¸Šä¸‹æ–‡è·å–æˆåŠŸæ“ä½œ"""
        similar_screenshots = self.search_similar_screenshots(context)
        successful_actions = []
        
        for sk in similar_screenshots:
            successful_actions.extend(sk.successful_actions)
        
        return successful_actions
    
    def get_failure_patterns(self, context: str) -> List[Dict]:
        """æ ¹æ®ä¸Šä¸‹æ–‡è·å–å¤±è´¥æ¨¡å¼"""
        similar_screenshots = self.search_similar_screenshots(context)
        failure_patterns = []
        
        for sk in similar_screenshots:
            failure_patterns.extend(sk.failed_actions)
        
        return failure_patterns
    
    def get_learning_insights(self, current_task: str) -> Dict[str, Any]:
        """è·å–å­¦ä¹ æ´å¯Ÿ"""
        # æœç´¢ç›¸ä¼¼ä»»åŠ¡
        similar_tasks = self.search_similar_tasks(current_task, top_k=5)
        
        # åˆ†ææˆåŠŸå’Œå¤±è´¥æ¨¡å¼
        successful_tasks = [t for t in similar_tasks if t.success]
        failed_tasks = [t for t in similar_tasks if not t.success]
        
        insights = {
            "similar_successful_tasks": len(successful_tasks),
            "similar_failed_tasks": len(failed_tasks),
            "success_rate": len(successful_tasks) / len(similar_tasks) if similar_tasks else 0,
            "recommendations": [],
            "common_successful_patterns": [],
            "common_failure_patterns": []
        }
        
        # æå–æˆåŠŸæ¨¡å¼
        if successful_tasks:
            # ç»Ÿè®¡å¸¸ç”¨æ“ä½œ
            action_counts = {}
            for task in successful_tasks:
                for action in task.actions:
                    action_type = action.get('action_type', 'unknown')
                    action_counts[action_type] = action_counts.get(action_type, 0) + 1
            
            # è·å–æœ€å¸¸ç”¨çš„æ“ä½œç±»å‹
            if action_counts:
                common_actions = sorted(action_counts.items(), key=lambda x: x[1], reverse=True)[:3]
                insights["common_successful_patterns"] = [action[0] for action in common_actions]
            else:
                insights["common_successful_patterns"] = []
        
        # æå–å¤±è´¥æ¨¡å¼
        if failed_tasks:
            # ç»Ÿè®¡å¤±è´¥åŸå› 
            error_counts = {}
            for task in failed_tasks:
                if task.error_message:
                    error_key = task.error_message  # å–å‰50ä¸ªå­—ç¬¦ä½œä¸ºé”™è¯¯ç±»å‹
                    error_counts[error_key] = error_counts.get(error_key, 0) + 1
            
            if error_counts:
                common_errors = sorted(error_counts.items(), key=lambda x: x[1], reverse=True)[:3]
                insights["common_failure_patterns"] = [error[0] for error in common_errors]
            else:
                insights["common_failure_patterns"] = []
        
        # ç”Ÿæˆå»ºè®®
        if insights["success_rate"] > 0.7:
            insights["recommendations"].append("æ­¤ç±»å‹ä»»åŠ¡æˆåŠŸç‡è¾ƒé«˜ï¼Œå¯ä»¥å‚è€ƒç›¸ä¼¼ä»»åŠ¡çš„æ“ä½œæ¨¡å¼")
        elif insights["success_rate"] < 0.3:
            insights["recommendations"].append("æ­¤ç±»å‹ä»»åŠ¡æŒ‘æˆ˜è¾ƒå¤§ï¼Œå»ºè®®å…ˆåˆ†æå¤±è´¥åŸå› ï¼Œå°è¯•ä¸åŒçš„æ“ä½œç­–ç•¥")
        
        return insights
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        total_tasks = len(self.task_experiences)
        successful_tasks = len([t for t in self.task_experiences if t.success])
        
        # ç»Ÿè®¡ä»»åŠ¡å’Œæˆªå›¾çš„ä½¿ç”¨æ¬¡æ•°å’Œå¤±è´¥æ¬¡æ•°
        task_usage_count = sum([t.usage_count for t in self.task_experiences])
        task_failure_count = sum([t.failure_count for t in self.task_experiences])
        screenshot_usage_count = sum([s.usage_count for s in self.screenshot_knowledge])
        screenshot_failure_count = sum([s.failure_count for s in self.screenshot_knowledge])
        
        # è·å–æœ€å¸¸ä½¿ç”¨çš„ä»»åŠ¡å’Œæˆªå›¾
        most_used_tasks = sorted(self.task_experiences, key=lambda x: x.usage_count, reverse=True)[:3]
        most_failed_tasks = sorted(self.task_experiences, key=lambda x: x.failure_count, reverse=True)[:3]
        most_used_screenshots = sorted(self.screenshot_knowledge, key=lambda x: x.usage_count, reverse=True)[:3]
        most_failed_screenshots = sorted(self.screenshot_knowledge, key=lambda x: x.failure_count, reverse=True)[:3]
        
        # è®¡ç®—å¤±è´¥ç‡
        task_failure_rate = task_failure_count / task_usage_count if task_usage_count > 0 else 0
        screenshot_failure_rate = screenshot_failure_count / screenshot_usage_count if screenshot_usage_count > 0 else 0
        
        return {
            "total_tasks": total_tasks,
            "successful_tasks": successful_tasks,
            "failed_tasks": total_tasks - successful_tasks,
            "success_rate": successful_tasks / total_tasks if total_tasks > 0 else 0,
            "total_screenshots": len(self.screenshot_knowledge),
            "task_usage_count": task_usage_count,  # æ–°å¢ï¼šä»»åŠ¡æ€»ä½¿ç”¨æ¬¡æ•°
            "task_failure_count": task_failure_count,  # æ–°å¢ï¼šä»»åŠ¡æ€»å¤±è´¥æ¬¡æ•°
            "task_failure_rate": task_failure_rate,  # æ–°å¢ï¼šä»»åŠ¡å¤±è´¥ç‡
            "screenshot_usage_count": screenshot_usage_count,  # æ–°å¢ï¼šæˆªå›¾æ€»ä½¿ç”¨æ¬¡æ•°
            "screenshot_failure_count": screenshot_failure_count,  # æ–°å¢ï¼šæˆªå›¾æ€»å¤±è´¥æ¬¡æ•°
            "screenshot_failure_rate": screenshot_failure_rate,  # æ–°å¢ï¼šæˆªå›¾å¤±è´¥ç‡
            "most_used_tasks": [{"task_id": t.task_id, "description": t.task_description[:50] + "...", "usage_count": t.usage_count} for t in most_used_tasks],
            "most_failed_tasks": [{"task_id": t.task_id, "description": t.task_description[:50] + "...", "failure_count": t.failure_count} for t in most_failed_tasks if t.failure_count > 0],
            "most_used_screenshots": [{"screenshot_id": s.screenshot_id, "context": s.task_context[:30] + "...", "usage_count": s.usage_count} for s in most_used_screenshots],
            "most_failed_screenshots": [{"screenshot_id": s.screenshot_id, "context": s.task_context[:30] + "...", "failure_count": s.failure_count} for s in most_failed_screenshots if s.failure_count > 0],
            "knowledge_base_size_mb": self._get_knowledge_base_size()
        }
    
    def _get_knowledge_base_size(self) -> float:
        """è·å–çŸ¥è¯†åº“å¤§å°ï¼ˆMBï¼‰"""
        total_size = 0
        for file_path in [self.experience_file, self.screenshot_file]:
            if os.path.exists(file_path):
                total_size += os.path.getsize(file_path)
        return total_size / (1024 * 1024)  # è½¬æ¢ä¸ºMB
    
    def clean_low_usage_data(self, 
                           usage_threshold: float = 0.2, 
                           min_usage_count: int = 1,
                           max_failure_rate: float = 0.8,  # æ–°å¢ï¼šæœ€å¤§å¤±è´¥ç‡é˜ˆå€¼
                           experience_type: str = "all") -> Dict[str, int]:
        """
        æ¸…é™¤ä½¿ç”¨ç‡ä½çš„æ•°æ®
        
        Args:
            usage_threshold: ä½¿ç”¨ç‡é˜ˆå€¼ (0.0-1.0)ï¼Œä½äºæ­¤å€¼çš„æ•°æ®å°†è¢«åˆ é™¤
            min_usage_count: æœ€å°ä½¿ç”¨æ¬¡æ•°ï¼Œä½äºæ­¤å€¼çš„æ•°æ®å°†è¢«åˆ é™¤
            max_failure_rate: æœ€å¤§å¤±è´¥ç‡é˜ˆå€¼ (0.0-1.0)ï¼Œé«˜äºæ­¤å€¼çš„æ•°æ®å°†è¢«åˆ é™¤
            experience_type: è¦æ¸…ç†çš„ç»éªŒç±»å‹ ("tasks", "screenshots", "all")
            
        Returns:
            åˆ é™¤ç»Ÿè®¡ä¿¡æ¯
        """
        # è®¡ç®—æœ€å¤§ä½¿ç”¨æ¬¡æ•°ç”¨äºé˜ˆå€¼è®¡ç®—
        max_task_usage = max([t.usage_count for t in self.task_experiences], default=0)
        max_screenshot_usage = max([s.usage_count for s in self.screenshot_knowledge], default=0)
        
        # è®¡ç®—å®é™…é˜ˆå€¼ï¼ˆæ¬¡æ•°æˆ–ç™¾åˆ†æ¯”ï¼‰
        task_threshold = max(int(max_task_usage * usage_threshold), min_usage_count)
        screenshot_threshold = max(int(max_screenshot_usage * usage_threshold), min_usage_count)
        
        stats = {
            "removed_tasks": 0,
            "remaining_tasks": 0,
            "removed_screenshots": 0,
            "remaining_screenshots": 0,
            "removed_for_high_failure_rate": 0  # æ–°å¢ï¼šå› é«˜å¤±è´¥ç‡åˆ é™¤çš„è®¡æ•°
        }
        
        # æ¸…ç†ä»»åŠ¡ç»éªŒ
        if experience_type in ["tasks", "all"]:
            original_count = len(self.task_experiences)
            self.task_experiences = [
                t for t in self.task_experiences 
                if (t.usage_count >= task_threshold and 
                    (t.usage_count == 0 or t.failure_count / t.usage_count <= max_failure_rate))
            ]
            removed_for_failure = sum(1 for t in self.task_experiences if 
                                   t.usage_count > 0 and t.failure_count / t.usage_count > max_failure_rate)
            stats["removed_tasks"] = original_count - len(self.task_experiences)
            stats["remaining_tasks"] = len(self.task_experiences)
            stats["removed_for_high_failure_rate"] += removed_for_failure
        
        # æ¸…ç†æˆªå›¾çŸ¥è¯†
        if experience_type in ["screenshots", "all"]:
            original_count = len(self.screenshot_knowledge)
            self.screenshot_knowledge = [
                s for s in self.screenshot_knowledge 
                if (s.usage_count >= screenshot_threshold and 
                    (s.usage_count == 0 or s.failure_count / s.usage_count <= max_failure_rate))
            ]
            removed_for_failure = sum(1 for s in self.screenshot_knowledge if 
                                   s.usage_count > 0 and s.failure_count / s.usage_count > max_failure_rate)
            stats["removed_screenshots"] = original_count - len(self.screenshot_knowledge)
            stats["remaining_screenshots"] = len(self.screenshot_knowledge)
            stats["removed_for_high_failure_rate"] += removed_for_failure
        
        # æ›´æ–°å‘é‡åŒ–æ•°æ®
        if stats["removed_tasks"] > 0:
            self.update_vectorization()
        
        # ä¿å­˜æ›´æ–°åçš„çŸ¥è¯†åº“
        self.save_knowledge()
        
        print(f"âœ… æ¸…ç†å®Œæˆ: "
              f"åˆ é™¤ {stats['removed_tasks']} ä¸ªä»»åŠ¡ç»éªŒ, "
              f"åˆ é™¤ {stats['removed_screenshots']} ä¸ªæˆªå›¾çŸ¥è¯†, "
              f"å…¶ä¸­ {stats['removed_for_high_failure_rate']} ä¸ªå› é«˜å¤±è´¥ç‡è¢«åˆ é™¤")
        
        return stats
    
    def record_task_failure(self):
        """è®°å½•å½“å‰æ£€ç´¢åˆ°çš„çŸ¥è¯†åœ¨ä»»åŠ¡æ‰§è¡Œä¸­å¤±è´¥"""
        updated_count = 0
        
        # æ›´æ–°ä»»åŠ¡ç»éªŒçš„å¤±è´¥è®¡æ•°
        if hasattr(self, '_current_retrieved_task_indices'):
            for idx in self._current_retrieved_task_indices:
                if 0 <= idx < len(self.task_experiences):
                    self.task_experiences[idx].failure_count += 1
                    updated_count += 1
        
        # æ›´æ–°æˆªå›¾çŸ¥è¯†çš„å¤±è´¥è®¡æ•°
        if hasattr(self, '_current_retrieved_screenshot_indices'):
            for idx in self._current_retrieved_screenshot_indices:
                if 0 <= idx < len(self.screenshot_knowledge):
                    self.screenshot_knowledge[idx].failure_count += 1
                    updated_count += 1
        
        # ä¿å­˜æ›´æ–°åçš„å¤±è´¥è®¡æ•°
        if updated_count > 0:
            self.save_knowledge()
            print(f"å·²æ›´æ–° {updated_count} æ¡çŸ¥è¯†è®°å½•çš„å¤±è´¥è®¡æ•°")
        
        # æ¸…ç©ºå½“å‰æ£€ç´¢è®°å½•
        self._current_retrieved_task_indices = []
        self._current_retrieved_screenshot_indices = []
        
        return updated_count