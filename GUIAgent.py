import os
import base64
import re
import time
from PIL import Image, ImageDraw
import pyautogui
from volcenginesdkarkruntime import Ark
from prompt import COMPUTER_USE_DOUBAO1
import matplotlib.pyplot as plt
from AutoGUI import PyAutoGUIActionExecutor
from ParseActionString import parse_action_string
import json
import io
from smart_position import find_position

class DoubaoUITarsGUI:
    def __init__(self, api_key=None):
        """
        åˆå§‹åŒ–Doubao UI-TARS GUIæ“ä½œå·¥å…· 
        
        Args:
            api_key: ç«å±±å¼•æ“API Keyï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡ARK_API_KEYè¯»å–
        """
        self.api_key = api_key or os.getenv('ARK_API_KEY')
        if not self.api_key:
            raise ValueError("è¯·æä¾›API Keyæˆ–è®¾ç½®ARK_API_KEYç¯å¢ƒå˜é‡")
            
        self.client = Ark(api_key=self.api_key)
        self.model_name = "doubao-1-5-ui-tars-250428"
        self.action_executor = PyAutoGUIActionExecutor()
        self.max_steps = 25
    
    def capture_screenshot(self, save_path=None):
        """
        æ•è·å±å¹•æˆªå›¾
        
        Args:
            save_path: æˆªå›¾ä¿å­˜è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶
            
        Returns:
            str: æˆªå›¾æ–‡ä»¶è·¯å¾„
        """
        if save_path is None:
            save_path = f"screenshot/screenshot_{int(time.time())}.png"
        
        screenshot = pyautogui.screenshot()
        new_size = (960,540)
        screenshot = screenshot.resize(new_size,Image.Resampling.LANCZOS)
        screenshot.save(save_path)
        self.screenshot_size = screenshot.size
        buffered = io.BytesIO()
        screenshot.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode()
        return img_base64
    
    def construct_messages(self, instruction, image_base64, language="Chinese"):
        system_prompt = COMPUTER_USE_DOUBAO1.format(instruction=instruction, language=language)

        message = [
                    {
                        "role": "user",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ]
        return message
    
    def inference(self, messages):
        response = self.client.chat.completions.create(
            # æŒ‰éœ€æ›¿æ¢ model id
            model=self.model_name,
            messages=messages,
            temperature=0.0,  # å›ºå®šæ¸©åº¦ä¿è¯è¾“å‡ºç¨³å®š
            stream=False       # æµå¼è·å–å“åº”ï¼ˆå¯é€‰ï¼‰
        )
        token = response.usage.total_tokens
        response = response.choices[0].message.content
        # print(response)
        if "```json" in response:
            response = response.split("```json")[1].split("```")[0]
        elif "```" in response:
            response = response.split("```")[1]
        else:
            # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
            response = response.strip()
        try:
            response = self.clean_json_response(response)
            response = json.loads(response)
        except Exception as e:
            print("jsonè§£æå¤±è´¥",e)
            print(response)
        return response,token
    def clean_json_response(self,response_text):
        """ç§»é™¤JSONä¸­çš„æ³¨é‡Šï¼Œä½¿å…¶å¯è§£æ"""
        # ç§»é™¤å•è¡Œæ³¨é‡Š
        lines = response_text.split('\n')
        cleaned_lines = []
        for line in lines:
            # æŸ¥æ‰¾æ³¨é‡Šå¼€å§‹ä½ç½®
            comment_pos = line.find('//')
            if comment_pos != -1:
                # æ£€æŸ¥æ³¨é‡Šæ˜¯å¦åœ¨å­—ç¬¦ä¸²å†…
                before_comment = line[:comment_pos]
                quote_count = before_comment.count('"')
                if quote_count % 2 == 0:  # å¶æ•°ä¸ªå¼•å·ï¼Œè¯´æ˜æ³¨é‡Šä¸åœ¨å­—ç¬¦ä¸²å†…
                    line = before_comment.rstrip(',').rstrip()
            cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)

    def run_autonomous_goal(self, goal):
        """è‡ªä¸»æ‰§è¡Œæ€»ç›®æ ‡"""
        print(f"ğŸ¯ å¼€å§‹æ‰§è¡Œæ€»ç›®æ ‡: {goal}")
        print(f"ğŸ“Š æœ€å¤§å°è¯•æ­¥éª¤: {self.max_steps}")
        self.current_step = 0
        action_message = None
        self.total_token = 0
        while self.current_step < self.max_steps:
            self.current_step += 1
            print(f"ğŸ”„ æ‰§è¡Œæ­¥éª¤ {self.current_step}/{self.max_steps}")
            try:
                # æˆªå›¾
                image = self.capture_screenshot()
            except Exception as e:
                print("æˆªå›¾å¤±è´¥",e)
                continue
            # AIåˆ†æå¹¶è§„åˆ’ä¸‹ä¸€æ­¥
            try:
                if not action_message:
                    action_message = self.construct_messages(instruction=goal, image_base64=image)
                else:
                    if len(action_message)>5:
                        action_message = [action_message[0]] + action_message[-4:]
                    action_message.append({
                        "role": "user",
                            "content": [
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/png;base64,{image}"
                                    }
                                }
                            ]
                    })
                ai_response,token = self.inference(messages=action_message)
                action_message = action_message[:-1]
                self.total_token += token
                print(f"AIæ€è€ƒ: {ai_response.get('thought', 'æ— ')}")
                print(f"AIå»ºè®®: {ai_response.get('action', 'æ— ')}")
                print(f"AIä½¿ç”¨tokenæ•°: {token}")
                action_message.append({
                    "role": "assistant",
                    "content": ai_response.get("thought")
                })
                if not ai_response:
                    print("AIåˆ†æå¤±è´¥")
                    continue
            except Exception as e:
                print("AIåˆ†æå¤±è´¥",e)
                continue

            # æ‰§è¡ŒAIå»ºè®®
            try:
                action_info = parse_action_string(ai_response.get("action"))
                if action_info:
                    message = self.action_executor.execute_parsed_action(action_info)
                    print("æ‰§è¡ŒæˆåŠŸ", message)
                    time.sleep(1)
                    if action_info.get("action_type") == "finished":
                        # print("AIåˆ¤æ–­ç›®æ ‡å·²å®Œæˆï¼")
                        return ai_response, True, self.total_token
                else:
                    print("æ‰§è¡Œå¤±è´¥")
            except Exception as e:
                print("æ‰§è¡Œå¤±è´¥",e)
                continue
        print(f"è¾¾åˆ°æœ€å¤§æ­¥éª¤æ•° {self.max_steps}ï¼Œç›®æ ‡æœªå®Œæˆ")
        return ai_response, False,self.total_token


# def main():
#     api_key = "6c08cf37-b093-4bae-a993-0e33fc3a1805"
#     doubao_gui = DoubaoUITarsGUI(api_key=api_key)
#     instruction = "åœ¨é£ä¹¦ä¸­æœç´¢è”ç³»äºº'æ¨æˆˆ å—äº¬é‚®ç”µå¤§å­¦ ç”µå­ä¿¡æ¯ 26å±Š'å¹¶å‘é€æ¶ˆæ¯'ä½ å¥½ï¼Œè¿™æ˜¯è‡ªåŠ¨åŒ–æµ‹è¯•'"
#     image = doubao_gui.capture_screenshot()
#     messages = doubao_gui.construct_messages(instruction=instruction, image_base64=image)
#     response = doubao_gui.inference(messages)
#     print(response)
#     action_info = parse_action_string(response.get("action"))
#     print(action_info)
#     doubao_gui.action_executor.execute_parsed_action(action_info)
    
# if __name__ == "__main__":
#     main()